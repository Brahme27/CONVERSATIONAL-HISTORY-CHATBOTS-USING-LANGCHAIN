{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b09a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # Load environment variables from .env file\n",
    "\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# print(\"GROQ_API_KEY:\", groq_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96864c1f",
   "metadata": {},
   "source": [
    "# Initialzing the Groq model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc6cbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000230175CDFC0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000230175CF220>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model=ChatGroq(\n",
    "    model=\"Gemma2-9b-It\",\n",
    "    groq_api_key=groq_api_key\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a3d700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "humanmessage=\"Hi my name is brahmesh,im an AI engineer\"\n",
    "\n",
    "response=model.invoke([\n",
    "    # SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=humanmessage)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "814a9b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Brahmesh, it's nice to meet you!  \\n\\nThat's awesome that you're an AI engineer. It's a really exciting field right now. \\n\\nWhat kind of AI work do you do?  Do you have any projects you're particularly proud of?\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b56d6de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Brahmesh, and you said you are an AI engineer!  \\n\\nIs there anything else you'd like to tell me about yourself? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 101, 'total_tokens': 140, 'completion_time': 0.072849637, 'prompt_time': 0.007743982, 'queue_time': 0.39306899700000003, 'total_time': 0.080593619}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--0ef03211-61f5-456f-8567-0e40b299e4e7-0', usage_metadata={'input_tokens': 101, 'output_tokens': 39, 'total_tokens': 140})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=humanmessage),\n",
    "    AIMessage(content=\"Hi Brahmesh, it's nice to meet you!  \\n\\nThat's awesome that you're an AI engineer. It's a really exciting field right now. \\n\\nWhat kind of AI work do you do?  Do you have any projects you're particularly proud of?\\n\"),\n",
    "    HumanMessage(content=\"Hey what is my name and what do i do\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db5dbf",
   "metadata": {},
   "source": [
    "# Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796d4e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from  langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "# while user is using the model,we should make sure that one \n",
    "# session is different from another\n",
    "\n",
    "\n",
    "store={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "\n",
    "    return store[session_id]\n",
    "\n",
    "# # Enables the model to remember previous messages using session history\n",
    "with_message_history=RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57b15e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9794fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is brahmesh,im an AI engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e97a22b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Brahmesh, it's great to meet you! \\n\\nBeing an AI engineer is such a cool field. What kind of projects are you working on? Are you into computer vision, natural language processing, or something else entirely?  \\n\\nI'm always interested in hearing about what people are building with AI.  \\n\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f3e91d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Brahmesh üòä \\n\\nI remember you told me when we first met!  \\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Playing with different sessions,wheather it is going to remember or not\n",
    "# 1) giving same session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey what is my name\")],\n",
    "    config=config1\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39a3fd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'd be happy to use it! üòä\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we are going to give different session id\n",
    "config2={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey what is my name\")],\n",
    "    config=config2\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ecaecf",
   "metadata": {},
   "source": [
    "## I can conclude that to preserve the chat history,make sure you maintain same session id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d335a8",
   "metadata": {},
   "source": [
    "# Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8eea62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8474eb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Brahmesh, it's nice to meet you!\\n\\nWhat can I do to help you today? üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 21, 'total_tokens': 49, 'completion_time': 0.050909091, 'prompt_time': 0.003462605, 'queue_time': 0.24607632399999999, 'total_time': 0.054371696}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--51f61651-e601-4351-925a-19a4d7883b8b-0', usage_metadata={'input_tokens': 21, 'output_tokens': 28, 'total_tokens': 49})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is brahmesh\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc84265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea788a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Brahmesh, it's nice to meet you!\\n\\nIs there anything I can help you with today? \\n\\nAs an AI assistant, I can help with a variety of tasks, such as:\\n\\n* **Generating creative content:**  I can write stories, poems, articles, and even code.\\n* **Answering your questions:** I have access to a vast store of knowledge and can answer your questions on a wide range of topics.\\n* **Summarizing text:**  I can condense large amounts of text into shorter summaries.\\n* **Translating languages:** I can translate text between many different languages.\\n\\n\\nLet me know how I can be of service!\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is brahmesh\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d54b7f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Brahmesh!  üòä \\n\\nI remember from our previous conversation.  Is there anything else I can help you with?  \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"heyy what is my name\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aabb399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more complexity \n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are a helpful assistant.Answer in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfe70cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Namaste Brahmesh! üòä  ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π‡§æ‡§Å ‡§π‡•Ç‡§Å‡•§ ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç ‡§Ø‡§æ ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡•á‡§∞‡•Ä ‡§Æ‡§¶‡§¶ ‡§ö‡§æ‡§π‡§ø‡§è? \\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke(\n",
    "    {\n",
    "        \"messages\":[HumanMessage(content=\"Hi my name is brahmesh\")],\n",
    "        \"language\":\"Hindi\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21916981",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6bec74dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡•á‡§∂! üòä \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•Ä ‡§Æ‡•Å‡§≤‡§æ‡•ò‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç‡•§ ‡§Æ‡•à‡§Ç ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•Ç‡§Å‡•§  ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á? \\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\":[HumanMessage(content=\"Hi my name is brahmesh\")],\n",
    "        \"language\":\"Hindi\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae188af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡•á‡§∂ ‡§π‡•à! üòä  \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\":[HumanMessage(content=\"Heyy what is my name\")],\n",
    "        \"language\":\"Hindi\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba28a7",
   "metadata": {},
   "source": [
    "# How to manage the converstion history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef99b774",
   "metadata": {},
   "source": [
    "## trim_messages is a function that shortens the chat history by keeping only the most important or recent messages so the conversation fits within the model‚Äôs limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b89634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0739a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hey what is my name and what do i do', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Your name is Brahmesh and you are an AI engineer.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='2+2=4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 2+3', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='2+3=5', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='enjoy talking to you', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I enjoy talking to you too!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=100,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi my name is brahmesh\"),\n",
    "    AIMessage(content=\"Hi Brahmesh, it's nice to meet you!  \\n\\nThat's awesome that you're an AI engineer. It's a really exciting field right now. \\n\\nWhat kind of AI work do you do?  Do you have any projects you're particularly proud of?\\n\"),\n",
    "    HumanMessage(content=\"Hey what is my name and what do i do\"),\n",
    "    AIMessage(content=\"Your name is Brahmesh and you are an AI engineer.\"),\n",
    "    HumanMessage(content=\"what is 2+2\"),\n",
    "    AIMessage(content=\"2+2=4\"),\n",
    "    HumanMessage(content=\"what is 2+3\"),\n",
    "    AIMessage(content=\"2+3=5\"),\n",
    "    HumanMessage(content=\"enjoy talking to you\"),\n",
    "    AIMessage(content=\"I enjoy talking to you too!\"),\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9da9f15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 2+3', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='2+3=5', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='enjoy talking to you', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I enjoy talking to you too!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now trim the tokens to 45\n",
    "# and see how the model is going to respond\n",
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi my name is brahmesh\"),\n",
    "    AIMessage(content=\"Hi Brahmesh, it's nice to meet you!  \\n\\nThat's awesome that you're an AI engineer. It's a really exciting field right now. \\n\\nWhat kind of AI work do you do?  Do you have any projects you're particularly proud of?\\n\"),\n",
    "    HumanMessage(content=\"Hey what is my name and what do i do\"),\n",
    "    AIMessage(content=\"Your name is Brahmesh and you are an AI engineer.\"),\n",
    "    HumanMessage(content=\"what is 2+2\"),\n",
    "    AIMessage(content=\"2+2=4\"),\n",
    "    HumanMessage(content=\"what is 2+3\"),\n",
    "    AIMessage(content=\"2+3=5\"),\n",
    "    HumanMessage(content=\"enjoy talking to you\"),\n",
    "    AIMessage(content=\"I enjoy talking to you too!\"),\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02b20ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have access to past conversations or any personal information about you, including your name.  \\n\\nIf you'd like to tell me your name, I'd be happy to use it! üòä  \\n\\n\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")| trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response=chain.invoke(\n",
    "    {\"messages\":messages + [HumanMessage(content=\"what is my name\")],\n",
    "        \"language\":\"English\"},\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf309a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got that message because we are using the trimmer and cut the maxtokens to 45\n",
    "# and it is not allowing the model to see the previous messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb74280f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked:  \"What is 2+3?\" \\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke(\n",
    "    {\"messages\":messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\":\"English\"},\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41bcc000",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets wrap this in the message history\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "config={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15d9715a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and don't know your name. Would you like to tell me? üòä  \\n\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\":messages + [HumanMessage(content=\"what is my name\")],\n",
    "        \"language\":\"English\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5063cbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a helpful assistant with no memory of past conversations, I have no record of any math problems you may have asked before. \\n\\nIf you have a math problem you'd like help with, please ask! I'm happy to assist. üòä  \\n\\n\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\":\"English\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26820b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
